{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import urllib.request\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#Generate pictures By P.Tor\n",
    "import csv\n",
    "import numpy as np\n",
    "import pygal\n",
    "import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza_pala_romana_URL = 'https://www.facebook.com/pg/Palapizzaromanabistrot/reviews/?ref=page_internal'\n",
    "# pizza_pala_romana_URL = 'https://www.facebook.com/pg/cafe.mademoiselle.bangkok.2015/reviews/?ref=page_internal'\n",
    "usr = \"scappingTeam@gmail.com\"\n",
    "pwd = \"torn2537\"\n",
    "shopName = 'romana'\n",
    "loop=20\n",
    "\n",
    "graphFileList=['romana','mademoiselle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = urllib.request.urlopen(pizza_pala_romana_URL).read()\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "data = soup.find_all(\"div\", class_=\"_5pbx userContent _3576\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This function will close notification of Chrome browser after log in facebook account.\n",
    "def handle_notification_Chrome():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "    chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "#Log in to facebook\n",
    "driver = handle_notification_Chrome()\n",
    "\n",
    "driver.get('https://www.facebook.com/')\n",
    "assert \"Facebook\" in driver.title\n",
    "elem = driver.find_element_by_id(\"email\")\n",
    "elem.send_keys(usr)\n",
    "elem = driver.find_element_by_id(\"pass\")\n",
    "elem.send_keys(pwd)\n",
    "elem.send_keys(Keys.RETURN)\n",
    "print(\"Log in sucessfully\")\n",
    "#Go to the page.\n",
    "driver.get(pizza_pala_romana_URL)\n",
    "#Dump source code of Facebook web page on target url\n",
    "\n",
    "last_i = 0 \n",
    "time.sleep(3) \n",
    "file_object = codecs.open(\"Dump_\"+shopName+\".txt\", \"w\", \"utf-8\") \n",
    "while last_i<loop: \n",
    "    last_i = last_i+1 \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") \n",
    "    time.sleep(2) \n",
    "print(\"==End of dump process==\") \n",
    "file_object.write(driver.page_source)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=codecs.open(\"Dump_\"+shopName+\".txt\", \"r\", \"utf-8\") \n",
    "source = f.read() \n",
    "\n",
    "soup = BeautifulSoup(source, 'html.parser') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>') \n",
    "\n",
    "def display_review(review):\n",
    "    for each_review in review:\n",
    "        print(each_review,'\\n')\n",
    "\n",
    "def remove_tags(text): \n",
    "    return TAG_RE.sub('', text) \n",
    "\n",
    "def get_review_from_html(soup):\n",
    "    data = soup.find_all(\"div\", class_=\"_5pbx userContent _3576\") \n",
    "    tag = \"\"\n",
    "    bag_of_data = []\n",
    "    for d in data: \n",
    "        tag = d.find(\"p\") \n",
    "        tag = remove_tags(str(tag)) \n",
    "        bag_of_data.append(tag)\n",
    "    return bag_of_data\n",
    "\n",
    "#Get review of the restuarant from HTML5 file.\n",
    "review = get_review_from_html(soup)\n",
    "print(\"Reviews: {}\".format(review))\n",
    "print(\"Type of Reviews: {}\".format(len(review)))\n",
    "#print(\"Reviews: {}\".format(review[:10]))\n",
    "#display_review(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize เวลาที่โพสต์\n",
    "#Get เวลา\n",
    "time_data = soup.find_all(\"span\", class_=\"timestampContent\")\n",
    "print(\"Length of Time_data: {}\".format(len(time_data)))\n",
    "year = ['2013', '2014', '2015', '2016', '2017']\n",
    "result = []\n",
    "count = 0\n",
    "\n",
    "def preprocess_word(time_data, year):\n",
    "    data = []\n",
    "    for i in range(len(time_data)):\n",
    "        #Remove tag of HTML \n",
    "        time_data[i] = remove_tags(str(time_data[i]))\n",
    "        #Split string list by white space. \n",
    "        time_data[i] = time_data[i].split(' ')\n",
    "\n",
    "        #Check whether white space in a word and then delete white space.\n",
    "        if '' in time_data[i]:\n",
    "            time_data[i].remove('')\n",
    "\n",
    "        # Delete 'เวลา' in a word.\n",
    "        if 'เวลา' in time_data[i]:\n",
    "            time_data[i].remove('เวลา')\n",
    "\n",
    "        # Delete 'น.' in a word.\n",
    "        if 'น.' in time_data[i]:\n",
    "            time_data[i].remove('น.')\n",
    "\n",
    "        # If each row does not have a year in last index, Then add year '2017' to last index\n",
    "        if len(time_data[i]) == 2:\n",
    "            time_data[i].insert(3, '2017')\n",
    "\n",
    "        #Check last index of each data is one of the '2014, 2015, 2016, 2017, 2018' or not \n",
    "        #If it does not, Then change the last index to '2018'\n",
    "        if time_data[i][-1] not in year:\n",
    "            time_data[i][-1] = '2017'\n",
    "        \n",
    "        data.append(time_data[i])\n",
    "        \n",
    "    return data\n",
    "\n",
    "time_data = preprocess_word(time_data, year)\n",
    "#Convert string list to string data type\n",
    "print(time_data[0])\n",
    "print(type(time_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare time data to CSV format\n",
    "date = []\n",
    "month = []\n",
    "year = []\n",
    "for i in range(len(time_data)):\n",
    "    date.append(int(time_data[i][0])) # For adding date to list\n",
    "    month.append(time_data[i][1]) # For adding month to list\n",
    "    year.append(int(time_data[i][2])) # For adding year to list\n",
    "#print(month, year)\n",
    "\n",
    "data = {'Date': date,\n",
    "         'Month': month,\n",
    "         'Year': year,\n",
    "       }\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "#Create excel writer\n",
    "df.to_csv('csv_'+shopName+'.csv', encoding='utf-8', index=False)\n",
    "print(\"Save sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum = 1\n",
    "# oldDateStr = None\n",
    "# with open('mademoiselle.csv', newline='') as csvfile:\n",
    "#     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "#     next(spamreader, None)\n",
    "#     for row in spamreader:\n",
    "#         dateStr = str(', '.join(row))\n",
    "#         if(oldDateStr == None):\n",
    "#             oldDateStr = dateStr\n",
    "#             continue\n",
    "#         if(dateStr != oldDateStr):\n",
    "#             print(oldDateStr+' '+str(sum))\n",
    "#             oldDateStr = dateStr\n",
    "#             sum = 1\n",
    "#         else:\n",
    "#             sum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthno = {\"มกราคม\": 1,\n",
    "            \"กุมภาพันธ์\": 2,\n",
    "            \"มีนาคม\": 3,\n",
    "            \"เมษายน\": 4,\n",
    "            \"พฤษภาคม\": 5,\n",
    "            \"มิถุนายน\": 6,\n",
    "            \"กรกฎาคม\": 7,\n",
    "            \"สิงหาคม\": 8,\n",
    "            \"กันยายน\": 9,\n",
    "            \"ตุลาคม\": 10,\n",
    "            \"พฤศจิกายน\": 11,\n",
    "            \"ธันวาคม\": 12}\n",
    "\n",
    "sum = 1\n",
    "oldMonthYearStr = None\n",
    "ls_result = []\n",
    "result_array = np.empty((4, 4))\n",
    "with open('csv_'+shopName+'.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    next(spamreader, None)\n",
    "    \n",
    "    for row in spamreader:\n",
    "        monthYear = str(','.join(row)).split(',')\n",
    "        monthYear[1] = str(monthno[str(monthYear[1])])\n",
    "        monthYearStr = str(','.join(monthYear))\n",
    "        if(oldMonthYearStr == None):\n",
    "            oldMonthYearStr = monthYearStr\n",
    "            continue\n",
    "        if(oldMonthYearStr != monthYearStr):\n",
    "            result = oldMonthYearStr+','+str(sum)\n",
    "            l = list(map(int, result.split(',')))\n",
    "            ls_result.append(l)\n",
    "#             print(oldMonthYearStr+','+str(sum))\n",
    "            oldMonthYearStr = monthYearStr\n",
    "            sum = 1\n",
    "        else:\n",
    "            sum += 1\n",
    "print(ls_result)\n",
    "\n",
    "a=np.array(ls_result)\n",
    "a=a[a[:,0].sort()]\n",
    "a=a[:,:,3]\n",
    "a=np.asarray(a[0])\n",
    "result=str(a).replace('\\n','').replace('[','').replace(']','')\n",
    "result = result.split(' ')\n",
    "result = list(map(int, result))\n",
    "result = str(', '.join(str(x) for x in result))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = codecs.open(\"result_\"+shopName+\".txt\", \"w\", \"utf-8\")\n",
    "file_object.write(result)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_chart = pygal.Dot(x_label_rotation=30)\n",
    "\n",
    "for shop in graphFileList:\n",
    "    f=codecs.open(\"result_\"+shop+\".txt\", \"r\", \"utf-8\") \n",
    "    summary = f.read() \n",
    "    l = list(map(int, summary.split(',')))\n",
    "    print(l)\n",
    "    dot_chart.add(shop, l)\n",
    "\n",
    "dot_chart.render_to_file('graph_result.svg') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
